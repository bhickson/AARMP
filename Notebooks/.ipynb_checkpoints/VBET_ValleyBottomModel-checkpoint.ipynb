{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VBET VAllEY BOTTOM MODEL\n",
    "#     The final output of the script is placed in nhd_dir as \"VBET_ValleyBottoms.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'Utilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8b93a8c73b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmerge_tool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[1;32mimport\u001b[0m \u001b[0mUtilities\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'Utilities'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Import necessary modules\n",
    "    from shapely.geometry import Point\n",
    "    from shapely.ops import linemerge\n",
    "    import rasterio as rio\n",
    "    import pandas as pd\n",
    "    import geopandas as gpd\n",
    "    import gdal, osr\n",
    "    import numpy as np\n",
    "    import os, shutil\n",
    "    import math\n",
    "    from rasterio.merge import merge as merge_tool\n",
    "    import Utilities as utils\n",
    "    import logging\n",
    "    \n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    overwrite = False\n",
    "    cleanup = False\n",
    "    nhd_dir = os.path.abspath(r\"M:\\Data\\NHD\")\n",
    "    \n",
    "    #print(\"Using NHD directory %s\" % nhd_dir)\n",
    "    \n",
    "    watersheds_dir = os.path.join(nhd_dir, \"Watersheds\")\n",
    "    \n",
    "    \"\"\"Large Slope Threshold: The value that represents the upper limit of slopes that will be included in the valley bottom \n",
    "    for the 'large' portions of the network.\"\"\"\n",
    "    large_slope_thresh = 2\n",
    "    \"\"\"Medium Slope Threshold: The value that represents the upper limit of slopes that will be included in the valley bottom\n",
    "     for the 'medium' portions of the network.\"\"\"\n",
    "    medium_slope_thresh = 5\n",
    "    \"\"\"Small Slope Threshold: The value that represents the upper limit of slopes that will be included in the valley bottoms\n",
    "     for the \"small\" portions of the network.\"\"\"\n",
    "    small_slope_thresh = 22\n",
    "    \n",
    "    \"\"\"High Drainage Area Threshold: The drainage area value in square meters. Streams whose upstream drainage area is greater \n",
    "    than this value will be considered the \"large\" portion of the network, and whose maximum valley bottom width will be \n",
    "    represented with the \"Large Buffer Size\" parameter.\"\"\"\n",
    "    high_drainage_area_thresh = 1000000  # (m2)\n",
    "    \"\"\"Low Drainage Area Threshold: The drainage area value in square meters. Streams whose upstream drainage area is less \n",
    "    than this value will be considered the \"small\" portion of the network, and whose maximum valley bottom width will be \n",
    "    represented with the \"Small Buffer Size\" parameter. Streams whose upstream drainage area is between the high and low \n",
    "    drainage area thresholds will be considered the \"medium\" portion of the network and their maximum valley bottom width \n",
    "    represented by the \"Medium Buffer Width\" parameter.\"\"\"\n",
    "    low_drainage_area_thresh = 40000     # (m2)\n",
    "    \n",
    "    createVBETValleyBottom(nhd_dir, large_slope_thresh, medium_slope_thresh, small_slope_thresh, high_drainage_area_thresh, low_drainage_area_thresh, overwrite=False, cleanup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRasterProj4(raster):\n",
    "    \"\"\" Function returns the projection of the input raster in proj4\"\"\"\n",
    "    fac = gdal.Open(raster)\n",
    "\n",
    "    ras_proj = fac.GetProjection()\n",
    "    spatialRef = osr.SpatialReference()\n",
    "\n",
    "    osr.UseExceptions()\n",
    "    # Apparently osr has difficulties identifying albers projections\n",
    "    prjText = ras_proj.replace('\"Albers\"', '\"Albers_Conic_Equal_Area\"')\n",
    "    spatialRef.ImportFromWkt(prjText)\n",
    "    ras_proj_proj4 = spatialRef.ExportToProj4()\n",
    "    return ras_proj_proj4\n",
    "\n",
    "def getRasterTransform(rasterLoc):\n",
    "    with rio.open(rasterLoc) as raster:\n",
    "        t = raster.affine\n",
    "        \n",
    "    return t\n",
    "\n",
    "\n",
    "def calculateGeom(row):\n",
    "    \"\"\" Is passed a row containing flowline geometry. Finds the node\n",
    "    in the geometry which is closest to center and then creates and \n",
    "    returns a 5m buffered polygon\"\"\"\n",
    "    geom = row[\"geometry\"]\n",
    "    if geom.geom_type == \"MultiLineString\":\n",
    "        geom = linemerge(geom)\n",
    "    num_nodes = len(geom.coords)\n",
    "    if not num_nodes == 2:\n",
    "        # IF LINESTRING IS NOT COMPOSED OF ONLY TWO NODES, GET THE NODE IN THE MIDDLE MOST OF THE LINE\n",
    "        point = Point(geom.coords[int(num_nodes/2)])\n",
    "        bufferSize = 10\n",
    "    else:\n",
    "        #print(\"Two point linestring...\")\n",
    "        # IF TWO POINT LINESTRING, SMALL STREAM ANYWAY. TAKE THE POINT WHICH IS AT THE END OF THE LINE\n",
    "        point = Point(geom.coords[-1])\n",
    "        bufferSize = 5\n",
    "    \n",
    "    poly = point.buffer(bufferSize)\n",
    "        \n",
    "    #points = createPoints(poly, fac_raster_loc)\n",
    "    \n",
    "    return poly\n",
    "\n",
    "\n",
    "def getSnappedPixelLocation(geom_x, geom_y, ras_aff):\n",
    "    #print(\"GEOM_X: \", geom_x, \"GEOM_Y: \", geom_y)\n",
    "    \"\"\" Returns set of upper-right snapped pixel locations in set as (x, y)\"\"\"\n",
    "    pix_xsize = ras_aff.a\n",
    "    pix_ysize = ras_aff.e\n",
    "    #print(pix_xsize, pix_ysize)\n",
    "\n",
    "    # get pixel coordinates of the geometry's bounding box\n",
    "    xvals = sorted([geom_x, ras_aff.c])\n",
    "    yvals = sorted([geom_y, ras_aff.f])\n",
    "    #print(\"XVALS: \", xvals)\n",
    "\n",
    "    diffx = xvals[1] - xvals[0]\n",
    "    diffy = yvals[1] - yvals[0]\n",
    "    #print(\"DIFFS: \", diffx, diffy)\n",
    "\n",
    "    pixel_xdiff = float(\"{0:.11f}\".format( diffx % pix_xsize ))  # get modulo pixel difference to float precision of 11 decimals\n",
    "    pixel_ydiff = float(\"{0:.11f}\".format( diffy % pix_ysize ))  # get modulo pixel difference to float precision of 11 decimals\n",
    "    #print(\"PIXEL DIFF: \", pixel_xdiff, pixel_ydiff)\n",
    "\n",
    "    #snapped pixel locations\n",
    "    if pixel_xdiff > pix_xsize / 2:\n",
    "        snapped_ulx = geom_x + (pix_xsize - pixel_xdiff)\n",
    "    else:\n",
    "        snapped_ulx = geom_x - pixel_xdiff\n",
    "   \n",
    "    if abs(pixel_ydiff) > abs(pix_ysize / 2):\n",
    "        snapped_uly = geom_y + (abs(pix_ysize) + pixel_ydiff)\n",
    "    else:\n",
    "        snapped_uly = geom_y - abs(pixel_ydiff)\n",
    "            \n",
    "    if snapped_ulx % pix_xsize != ras_aff.c % pix_xsize:\n",
    "        print(snapped_ulx % pix_xsize)\n",
    "        raise ValueError(\"BAD PIXEL VALUE FOR ULX - \", snapped_ulx)\n",
    "    if snapped_uly % pix_ysize != ras_aff.f % pix_ysize:\n",
    "        print(snapped_uly % pix_ysize)\n",
    "        raise ValueError(\"BAD PIXEL VALUE FOR ULY - \", snapped_uly)\n",
    "    \n",
    "    return {\"x\": snapped_ulx, \"y\": snapped_uly}\n",
    "\n",
    "\n",
    "def createPoints(row):\n",
    "    #print(\"CREATE POINTS: \", row)\n",
    "    global rowcount\n",
    "    rowcount += 1\n",
    "    if rowcount % 10000 == 0:\n",
    "        print(\"Feature #: \", rowcount)\n",
    "    \n",
    "    geom_b = row[\"fac_poly\"].bounds\n",
    "\n",
    "    ul = getSnappedPixelLocation(geom_b[0], geom_b[3], rt)\n",
    "    lr = getSnappedPixelLocation(geom_b[2], geom_b[1], rt)\n",
    "\n",
    "    outshape_x = int(abs(lr[\"x\"] - ul[\"x\"]))\n",
    "    outshape_y = int(abs(ul[\"y\"] - lr[\"y\"]))\n",
    "    outshapex_inPixels = int(outshape_x/abs(rt.a))\n",
    "    outshapey_inPixels = int(outshape_y/abs(rt.e))\n",
    "    \n",
    "    if outshapex_inPixels == 0 or outshape_y == 0:\n",
    "        raise ValueError(\"Snapped bounding box is not correct\", \n",
    "                         outshapex_inPixels, outshapey_inPixels)\n",
    "    \n",
    "    half_x_size = abs(rt.a)/2\n",
    "    half_y_size = abs(rt.e)/2\n",
    "    \n",
    "    polygon_internal_points = []\n",
    "    polygon_external_points = []\n",
    "    \n",
    "    for x in range(outshapex_inPixels):\n",
    "        pointx = (ul[\"x\"] + half_x_size) + (x * abs(rt.a))\n",
    "        for y in range(outshapey_inPixels):\n",
    "            pointy = (ul[\"y\"] - half_y_size) - (y * abs(rt.e))\n",
    "            point = Point(pointx, pointy)\n",
    "            \n",
    "            if point.within(row[\"fac_poly\"]): # IF WITHIN THE BUFFERED POINT\n",
    "                #print(\"POINT: \", point)\n",
    "                #props = {'Type': str(feature[\"properties\"][\"Type\"]),\n",
    "                #         'Class': int(feature[\"properties\"]['Class'])}\n",
    "                #count += 1\n",
    "                polygon_internal_points.append(point)\n",
    "                #pointput.write({'geometry': mapping(point), 'properties': props}\n",
    "            else:\n",
    "                polygon_external_points.append(point)\n",
    "                \n",
    "    if len(polygon_internal_points) != 0:\n",
    "        return getMaxRasterValues(polygon_internal_points)\n",
    "    else:\n",
    "        # IF NONE ARE IN THE BUFFERED AREA, RETURN ALL OF THEM\n",
    "        #print(\"NUMBER OF INTERSECTING POINTS IS 0: \", len(polygon_internal_points))\n",
    "        return getMaxRasterValues(polygon_external_points)\n",
    "        #print(\"NUMBER OF POINTS: \", len(polygon_internal_points))\n",
    "        #raise ValueError(\"PROBLEM at feature \", row)\n",
    "    \n",
    "def getMaxRasterValues(points):\n",
    "    \"\"\" GET LIST OF POINTS AND CALCULATES THE MAXIMUM VALUES OF ALL THE POINST OF THE fac_raster\"\"\"\n",
    "    values = []\n",
    "    for point in points:\n",
    "        for val in fac_raster.sample([(point.x, point.y)]):\n",
    "            values.append(val[0])\n",
    "        \n",
    "    return max(values)\n",
    "\n",
    "def getResAndExtent(raster_file):\n",
    "    \"\"\" RETURN THE RESOLUTION AND EXTENT OF THE RASTER AS A LIST [resx, resy, xmin, ymin, xmax, ymax]\"\"\"\n",
    "    with rio.open(raster_file) as ras:\n",
    "        ymax = ras.profile['affine'][5]\n",
    "        xmin = ras.profile['affine'][2]\n",
    "        height = ras.profile['height']\n",
    "        width = ras.profile['width']\n",
    "        resx = ras.profile['affine'][0]\n",
    "        resy = ras.profile['affine'][4]\n",
    "        ymin = ymax + (height * resy)\n",
    "        xmax = xmin + (width * resx)\n",
    "\n",
    "        return [abs(resx), abs(resy), str(xmin), str(ymin), str(xmax), str(ymax)]\n",
    "    \n",
    "def bufferLines(row):\n",
    "    geom = row.geometry\n",
    "    fac = row[watershed_col]\n",
    "    \n",
    "    # log of 1 is 0, can't divide by zero. Also, a Flow accumulation value of 1 or zero is a misread, essentially minimum buffer size\n",
    "    if fac <= 1:\n",
    "        fac = 2\n",
    "\n",
    "    \"\"\"Simple equation which correlates the flow accumulation values (fac), e.g. watershed size,\n",
    "    to the appropriate valley bottom buffer\"\"\"\n",
    "    buffersize = math.sqrt(fac)/(math.log(fac, 10) * (4/3))\n",
    "    \n",
    "    return geom.buffer(buffersize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createVBETValleyBottom(nhdDir, lrgSlopeThresh, medSlopeThresh, smSlopeThresh, overwrite=False, cleanup=False):\n",
    "    \"\"\" Creates a single output valley bottom using the VBET methodology. First iterates watersheds directory \n",
    "    for each HUC4 watersheds and \"\"\"\n",
    "    \n",
    "    # The final output of the script\n",
    "    vbet_allwatersheds = os.path.join(nhd_dir, \"VBET_ValleyBottoms.tif\")\n",
    "    \n",
    "    # Watershed Size Column Name\n",
    "    watershed_col = \"WtrShdSize\"\n",
    "    \n",
    "    if not os.path.exists(vbet_allwatersheds) or overwrite:\n",
    "        logging.info(\"\\nValley Bottom Raster based on VBET methodology doesn't exists. Beginning creation.\\n\")\n",
    "        # Final output file doesn't exist, begin creation\n",
    "        \n",
    "        watershedsDir = os.path.join(nhdDir, \"Watersheds\")\n",
    "        utils.useDirectory(watershedsDir)\n",
    "        flow_acc_thresh = 2000  # minimum flow accumulation size to identify stream\n",
    "        ValleyBottomRastersPrep.vb_prep(watershedsDir, flow_initiation_threshold=flow_acc_thresh)\n",
    "        \n",
    "        # Need to divide by 1000 because of the PercentRise calculation used in Esri's Slope Determination. Just a component of predictor variables.\n",
    "        lrgSlopeThresh = lrgSlopeThresh/1000\n",
    "        medSlopeThresh = medSlopeThresh/1000\n",
    "        smSlopeThresh = smSlopeThresh/1000\n",
    "        \n",
    "        for w_dir in os.listdir(watershedsDir):\n",
    "            logging.debug(\"--- BEGINNING ON WATERSHED %s ---\" % w_dir)\n",
    "            watershed_dir = os.path.join(watershedsDir, w_dir)\n",
    "            for subdir in os.listdir(watershed_dir):\n",
    "                if \"Rasters\" in subdir:\n",
    "                    rasters_dir = os.path.join(watershed_dir, subdir)\n",
    "                if \"GDB\" in subdir:\n",
    "                    geodatabase = os.path.join(watershed_dir, subdir)\n",
    "                    \n",
    "            fac_raster_loc = os.path.join(rasters_dir, \"fac.tif\")\n",
    "            preds_dir = os.path.join(rasters_dir, \"Predictors\")\n",
    "            dem = os.path.join(preds_dir, \"elev_meters.tif\")\n",
    "            slope_ras = os.path.join(preds_dir, \"DEM_Slope_Radians.tif\")\n",
    "        \n",
    "            if not os.path.exists(slope_ras):\n",
    "                logging.error(\"Slope raster does not exist. Run RSAC preprocessing script from ArcGIS python environment.\")\n",
    "                raise Exception\n",
    "                \n",
    "            flowlines_vector = os.path.join(watershed_dir, \"NHD_Flowlines_buffered.shp\")\n",
    "            flowlines_raster = os.path.join(watershed_dir, \"NHD_Flowlines_buffered.tif\")\n",
    "            \n",
    "            if not os.path.exists(flowlines_raster) or overwrite:\n",
    "                logging.info(\"%s doesn't exists. Beginning creation...\" % flowlines_raster)\n",
    "                \n",
    "                logging.debug(\"Reading in NHD flowlines feature class from geodatabase...\")\n",
    "                flowlines = gpd.GeoDataFrame.from_file(geodatabase, layer='NHDFlowline')\n",
    "        \n",
    "                raster_crs = getRasterProj4(fac_raster_loc)\n",
    "                logging.debug(\"Reprojecting flowlines dataframe to FAC raster projection...\")\n",
    "                flowlines.to_crs(raster_crs, inplace=True)\n",
    "        \n",
    "                # Cleanup flowlines table by removing all columns not geometry\n",
    "                all_columns = flowlines.columns.tolist()\n",
    "                all_columns.remove('geometry')\n",
    "                \n",
    "                # TODO - select only flowlines which are true in-ground streams. Do not include canals, culverts, etc\n",
    "                \n",
    "                flowlines.drop(all_columns, axis=1, inplace=True)\n",
    "                #print(flowlines.columns)\n",
    "        \n",
    "                # Create new column 'fac_poly' (Flow accumulation poly) and calculate the single point geometry \n",
    "                #     of the vertex. This is used to extract the flow accumulation value of the line string. \n",
    "                logging.debug(\"Finding node on flowline and buffering...\")\n",
    "                flowlines['fac_poly'] = flowlines.apply(calculateGeom, axis=1)\n",
    "        \n",
    "                # Get raster info. Used as inherited variable in createPoints function below\n",
    "                rt = getRasterTransform(fac_raster_loc)\n",
    "        \n",
    "                rowcount = 0\n",
    "                # fac_points COLUMN CONTAINS POINTS IN A 10m BUFFER\n",
    "                with rio.open(fac_raster_loc) as fac_raster:\n",
    "                    #flowlines['fac_points'] = flowlines.apply(createPoints, axis=1)\n",
    "                    flowlines[watershed_col] = flowlines.apply(createPoints, axis=1)\n",
    "        \n",
    "                # Convert Watershed size column column to integer\n",
    "                flowlines[watershed_col] = flowlines[watershed_col].apply(pd.to_numeric)\n",
    "        \n",
    "                #print(flowlines.columns)\n",
    "        \n",
    "                # Buffer each flowline by its watershed size\n",
    "                flowlines[\"geometry\"] = flowlines.apply(bufferLines, axis=1)\n",
    "        \n",
    "                # Drop the now unused fac_poly column. Cleaner and can't write to file with two geometry columns\n",
    "                flowlines.drop([\"fac_poly\"], axis=1, inplace=True)\n",
    "                # Write out to shapefile\n",
    "                logging.debug(\"Writing out flowline buffers to file: %s\" % flowlines_vector)\n",
    "                flowlines.to_file(flowlines_vector)\n",
    "        \n",
    "                logging.debug(\"Reading in slope raster\")\n",
    "                with rio.open(slope_ras) as sloperas:\n",
    "                    slope_band = sloperas.read().astype(rio.float32)\n",
    "        \n",
    "                temp_dir = os.path.join(watershed_dir, \"VBET_temp\")\n",
    "                if not os.path.exists(temp_dir):\n",
    "                    os.mkdir(temp_dir)\n",
    "                \n",
    "                clipped_rasters = {}\n",
    "                # Write the small, medium, and large designations to their own temporary files\n",
    "                for size in [\"Small\", \"Medium\", \"Large\"]:\n",
    "                    outfile_feats = os.path.join(temp_dir, \"FlowlinesBuffered_\" + size + \".shp\")\n",
    "        \n",
    "                    if not os.path.exists(outfile_feats):\n",
    "                        print(\"Writing features to shapefile %s ...\" % outfile_feats)\n",
    "                        flowlines.loc[flowlines[\"drainage_class\"] == size].to_file(outfile_feats)\n",
    "                        \n",
    "                    else:\n",
    "                        print(\"%s already exists\" % outfile_feats)\n",
    "                        \n",
    "                    # Rasterize the polygons\n",
    "                    outbuffer_ras = os.path.join(temp_dir, \"FlowlinesBuffer_\" + size + \".tif\")\n",
    "                    if not os.path.exists(outbuffer_ras):\n",
    "                        print(\"Rasterizing %s ...\" % outfile_feats)\n",
    "                        rasterinfo = getResAndExtent(slope_ras)\n",
    "                        extent = \" \".join(rasterinfo[2:])\n",
    "                        res_x = str(rasterinfo[0])\n",
    "                        res_y = str(rasterinfo[1])\n",
    "                        opts = \"-a \" + watershed_col + \" -a_nodata 0 -tr \" + res_x + \" \" + res_y + \" -ot uint8 -te \" + extent\n",
    "                        #print(opts)\n",
    "                        gdal.Rasterize(outbuffer_ras, outfile_feats, options=opts)\n",
    "                    \n",
    "                    # Based on the size designation of the buffer zones threshold, clip the buffer zones to areas below the threshold\n",
    "                    if size == \"Small\":\n",
    "                        slope_threshold = smSlopeThresh\n",
    "                    elif size == \"Medium\":\n",
    "                        slope_threshold = medSlopeThresh\n",
    "                    elif size == \"Large\":\n",
    "                        slope_threshold = lrgSlopeThresh\n",
    "        \n",
    "                    outclip_ras = \"FlowlineBuffer_SlopeClip\" + str(slope_threshold*1000) + \"_\" + size + \".tif\"\n",
    "                    outclip_ras_loc = os.path.join(temp_dir, outclip_ras)\n",
    "                    clipped_rasters[size] = outclip_ras_loc\n",
    "        \n",
    "                    if not os.path.exists(outclip_ras_loc) or overwrite:\n",
    "                        with rio.open(outbuffer_ras) as flowlineBuffers_ras:\n",
    "                            flowline_band = flowlineBuffers_ras.read().astype(rio.float32)\n",
    "                            kwargs = flowlineBuffers_ras.profile\n",
    "        \n",
    "                        kwargs.update(\n",
    "                            dtype=rio.float32\n",
    "                        )\n",
    "        \n",
    "                        logging.debug(\"Clipping slope to flowline buffer region...\")\n",
    "                        slope_clip = np.where(flowline_band > 1, slope_band, 0)\n",
    "        \n",
    "                        logging.debug(\"Starting slope clip on %s with slope threshold %s\" % (outclip_ras_loc, str(slope_threshold)))\n",
    "                        flowline_clip = np.where(slope_clip > slope_threshold, 0, flowline_band)\n",
    "        \n",
    "                        with rio.open(outclip_ras_loc, \"w\", **kwargs) as dst:\n",
    "                            dst.write(flowline_clip.astype(rio.float32))\n",
    "        \n",
    "                return clipped_rasters # returns dictionary of raster paths for small, medium, and large\n",
    "        \n",
    "                # Merge individual vb rasters to one\n",
    "                logging.info(\"Merging raster sizes to final at %s\" % flowlines_raster)            \n",
    "                with rio.open(clipped_rasters[\"Small\"]) as small_ras:\n",
    "                    small_array = small_ras.read().astype(float)\n",
    "                with rio.open(clipped_rasters[\"Medium\"]) as med_ras:\n",
    "                    medium_array = med_ras.read().astype(float)\n",
    "                with rio.open(clipped_rasters[\"Large\"]) as large_ras:\n",
    "                    large_array = large_ras.read().astype(float)\n",
    "                    kwargs = large_ras.profile\n",
    "        \n",
    "                # numpy maximum only allows comparison of two arrays at a time. weird\n",
    "                flowline_buffer_array = np.maximum(small_array, medium_array)\n",
    "                flowline_buffer_array = np.maximum(flowline_buffer_array, large_array)\n",
    "        \n",
    "                with rio.open(flowlines_raster, 'w', **kwargs) as dst:\n",
    "                    dst.write(flowline_buffer_array.astype(rio.float32))\n",
    "        \n",
    "                if cleanup == True:\n",
    "                    for file in os.listdir(temp_dir):\n",
    "                        fpath = os.path.join(temp_dir, file)\n",
    "                        shutil.remove(fpath)\n",
    "                    os.rmdir(temp_dir)\n",
    "                    \n",
    "                    \n",
    "        # Merge All Watershed VBs together\n",
    "        files = []\n",
    "    \n",
    "        for w_dir in os.listdir(watersheds_dir):\n",
    "            watershed_dir = os.path.join(watersheds_dir, w_dir)\n",
    "            for file in os.listdir(watershed_dir):\n",
    "                if file == \"NHD_Flowlines_buffered.tif\":\n",
    "                    fpath = os.path.join(watershed_dir, file)\n",
    "                    files.append(fpath)\n",
    "    \n",
    "        logging.info(\"Beginning merge of :\\n\\t%s\" % (\"\\n\\t\".join(files)))\n",
    "        sources = [rio.open(f) for f in files]\n",
    "        merged_array, output_transform = merge_tool(sources)\n",
    "    \n",
    "        profile = sources[0].profile\n",
    "        profile['transform'] = output_transform\n",
    "        profile['height'] = merged_array.shape[1]\n",
    "        profile['width'] = merged_array.shape[2]\n",
    "        \n",
    "        profile.update(dtype=np.float32)\n",
    "    \n",
    "        #print(profile)\n",
    "    \n",
    "        logging.debug(\"Writing merge out...\")\n",
    "        with rio.open(vbet_allwatersheds, 'w', **profile) as dst:\n",
    "            dst.write(merged_array.astype(np.float32))\n",
    "            \n",
    "        logging.info(\"Finished merging files to %s\" % vbet_allwatersheds)\n",
    "    \n",
    "    else:\n",
    "        logging.info(\"%s Already exists and no overwrite set\" % vbet_allwatersheds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geodatabase = r\"M:\\Data\\ValleyBottoms\\Watersheds\\1507\\NHDPlus_H_1507_GDB.gdb\"\n",
    "flowlines_vaa = gpd.GeoDataFrame.from_file(geodatabase, layer='NHDPlusFlowlineVAA')\n",
    "flowlines = gpd.GeoDataFrame.from_file(geodatabase, layer='NHDFlowline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permanent_Identifier</th>\n",
       "      <th>FDate</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>GNIS_ID</th>\n",
       "      <th>GNIS_Name</th>\n",
       "      <th>LengthKM</th>\n",
       "      <th>ReachCode</th>\n",
       "      <th>FlowDir</th>\n",
       "      <th>WBArea_Permanent_Identifier</th>\n",
       "      <th>FType</th>\n",
       "      <th>FCode</th>\n",
       "      <th>MainPath</th>\n",
       "      <th>InNetwork</th>\n",
       "      <th>VisibilityFilter</th>\n",
       "      <th>Shape_Length</th>\n",
       "      <th>NHDPlusID</th>\n",
       "      <th>VPUID</th>\n",
       "      <th>Enabled</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153172495</td>\n",
       "      <td>2015-11-14T18:33:03</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.439</td>\n",
       "      <td>15070104002860</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>460</td>\n",
       "      <td>46007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>4.000030e+13</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>(LINESTRING Z (-113.2393364680036 34.078086813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111549368</td>\n",
       "      <td>2015-11-14T18:36:29</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.293</td>\n",
       "      <td>15070203002016</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>460</td>\n",
       "      <td>46007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>4.000030e+13</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>(LINESTRING Z (-113.2066020680543 32.541226682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153154459</td>\n",
       "      <td>2015-11-14T18:38:05</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.606</td>\n",
       "      <td>15070201009018</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>460</td>\n",
       "      <td>46007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>4.000030e+13</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>(LINESTRING Z (-113.2053928680562 32.816411282...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153145207</td>\n",
       "      <td>2015-11-14T18:50:34</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.239</td>\n",
       "      <td>15070201000866</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>460</td>\n",
       "      <td>46007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>4.000030e+13</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>(LINESTRING Z (-113.2153698013741 32.954081082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153145208</td>\n",
       "      <td>2015-11-14T18:57:35</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.035</td>\n",
       "      <td>15070201000866</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>460</td>\n",
       "      <td>46007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>4.000030e+13</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>(LINESTRING Z (-113.2150438013746 32.953932682...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Permanent_Identifier                FDate  Resolution GNIS_ID GNIS_Name  \\\n",
       "0            153172495  2015-11-14T18:33:03           2    None      None   \n",
       "1            111549368  2015-11-14T18:36:29           2    None      None   \n",
       "2            153154459  2015-11-14T18:38:05           2    None      None   \n",
       "3            153145207  2015-11-14T18:50:34           2    None      None   \n",
       "4            153145208  2015-11-14T18:57:35           2    None      None   \n",
       "\n",
       "   LengthKM       ReachCode  FlowDir WBArea_Permanent_Identifier  FType  \\\n",
       "0     0.439  15070104002860        1                        None    460   \n",
       "1     2.293  15070203002016        1                        None    460   \n",
       "2     1.606  15070201009018        1                        None    460   \n",
       "3     0.239  15070201000866        1                        None    460   \n",
       "4     0.035  15070201000866        1                        None    460   \n",
       "\n",
       "   FCode  MainPath  InNetwork  VisibilityFilter  Shape_Length     NHDPlusID  \\\n",
       "0  46007         0          1                 0      0.004148  4.000030e+13   \n",
       "1  46007         0          1                 0      0.004048  4.000030e+13   \n",
       "2  46007         0          1                 0      0.016232  4.000030e+13   \n",
       "3  46007         0          1                 0      0.002231  4.000030e+13   \n",
       "4  46007         0          1                 0      0.000358  4.000030e+13   \n",
       "\n",
       "  VPUID  Enabled                                           geometry  \n",
       "0  1507        1  (LINESTRING Z (-113.2393364680036 34.078086813...  \n",
       "1  1507        1  (LINESTRING Z (-113.2066020680543 32.541226682...  \n",
       "2  1507        1  (LINESTRING Z (-113.2053928680562 32.816411282...  \n",
       "3  1507        1  (LINESTRING Z (-113.2153698013741 32.954081082...  \n",
       "4  1507        1  (LINESTRING Z (-113.2150438013746 32.953932682...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NHDPlusID', 'StreamLeve', 'StreamOrde', 'StreamCalc', 'FromNode',\n",
       "       'ToNode', 'HydroSeq', 'LevelPathI', 'PathLength', 'TerminalPa',\n",
       "       'ArbolateSu', 'Divergence', 'StartFlag', 'TerminalFl', 'UpLevelPat',\n",
       "       'UpHydroSeq', 'DnLevel', 'DnLevelPat', 'DnHydroSeq', 'DnMinorHyd',\n",
       "       'DnDrainCou', 'FromMeas', 'ToMeas', 'ReachCode', 'RtnDiv', 'Thinner',\n",
       "       'VPUIn', 'VPUOut', 'AreaSqKm', 'TotDASqKm', 'DivDASqKm', 'MaxElevRaw',\n",
       "       'MinElevRaw', 'MaxElevSmo', 'MinElevSmo', 'Slope', 'SlopeLenKm',\n",
       "       'ElevFixed', 'HWType', 'HWNodeSqKm', 'StatusFlag', 'VPUID', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowlines = pd.merge(flowlines, flowlines_vaa, on='business_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
